{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a086b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57cb1310",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"VicAIAgen2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "548e23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb2a459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage, AIMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import shutil\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import MessagesState\n",
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "#search = TavilySearchResults(max_results=3)\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Add these to your state if you haven't already:\n",
    "@dataclass\n",
    "class MessagesState:\n",
    "    messages: List[BaseMessage]\n",
    "    last_summarized_at: int = 0  # <-- Add this field!\n",
    "\n",
    "\n",
    "\n",
    "def tavily_search_full(query: str) -> str:\n",
    "    \"\"\"Searches the web using Tavily and returns detailed content.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TAVILY_API_KEY}\"\n",
    "    }\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"max_results\": 3,\n",
    "        \"include_raw_content\": True,\n",
    "        \"search_depth\": \"advanced\"\n",
    "    }\n",
    "    response = requests.post(\"https://api.tavily.com/search\", headers=headers, json=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    results = data.get(\"results\", [])\n",
    "    formatted = \"\"\n",
    "    for result in results:\n",
    "        formatted += f\"Title: {result['title']}\\nURL: {result['url']}\\nContent: {result.get('content', '')[:1000]}...\\n\\n\"\n",
    "    return formatted\n",
    "\n",
    "\n",
    "def move_file(source: str, destination: str) -> str:\n",
    "    \"\"\"\n",
    "    Move a file from `source` to `destination`.\n",
    "    If destination is a directory (ends with a slash or has no extension),\n",
    "    it will use the same filename.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(source):\n",
    "        return f\"‚ùå Source file not found: {source}\"\n",
    "\n",
    "    # Check if destination is a directory\n",
    "    _, ext = os.path.splitext(destination)\n",
    "    looks_like_dir = destination.endswith(os.sep) or ext == \"\"\n",
    "    if looks_like_dir:\n",
    "        os.makedirs(destination, exist_ok=True)\n",
    "        filename = os.path.basename(source)\n",
    "        destination = os.path.join(destination, filename)\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        shutil.move(source, destination)\n",
    "        return f\"‚úÖ Moved `{source}` ‚Üí `{destination}`\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Failed to move file: {e}\"\n",
    "    \n",
    "def read_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Read and return the content of a text file.\n",
    "    Only use for small text files.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        return f\"‚ùå File not found: {path}\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            return f\"üìÑ Contents of `{path}`:\\n/n{content[:1000]}{'...' if len(content) > 1000 else ''}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Failed to read file: {e}\"\n",
    "\n",
    "\n",
    "def list_files(directory: str) -> str:\n",
    "    \"\"\"\n",
    "    Lists the files and subdirectories in the given directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return f\"‚ùå Directory does not exist: {directory}\"\n",
    "    try:\n",
    "        items = os.listdir(directory)\n",
    "        if not items:\n",
    "            return f\"üìÇ Directory is empty: {directory}\"\n",
    "        return f\"üìÇ Contents of `{directory}`:\\n\" + \"\\n\".join(f\"- {item}\" for item in items)\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Failed to list directory: {e}\"\n",
    "    \n",
    "mpl.use('Agg')\n",
    "\n",
    "def _parse_oceanwave_file(filename):\n",
    "    \"\"\"Parses a single OceanWave3D data file.\"\"\"\n",
    "    data_list = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            row = []\n",
    "            for part in parts:\n",
    "                try:\n",
    "                    value = float(part)\n",
    "                except ValueError:\n",
    "                    # Try to handle Fortran-style scientific notation like '1.234-56'\n",
    "                    match = re.match(r'(\\d+\\.\\d+)([+-]\\d+)', part)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            value = float(f\"{match.group(1)}E{match.group(2)}\")\n",
    "                        except ValueError:\n",
    "                            value = 0.0 # Fallback if conversion still fails\n",
    "                    else:\n",
    "                        value = 0.0 # Fallback if it's not a standard float or known scientific notation\n",
    "                row.append(value)\n",
    "            # Ensure the row has the expected number of columns (X, Y, Z, optional 4th)\n",
    "            if len(row) >= 3: # We need at least X, Y, Z\n",
    "                 # Keep only the first 3 or 4 columns depending on expected format\n",
    "                 # Sticking to 4 based on original code\n",
    "                 if len(row) == 4:\n",
    "                     data_list.append(row)\n",
    "                 elif len(row) == 3:\n",
    "                     # If only 3 columns, add a dummy 4th if needed, or adjust logic\n",
    "                     # For now, assume the original 4-column structure was intended\n",
    "                     # If your files only have 3 (X,Y,Z), adjust this part and slicing below\n",
    "                     pass # Or append [row[0], row[1], row[2], 0.0] if 4 are always needed\n",
    "\n",
    "    if not data_list:\n",
    "        # Handle empty or unparseable file\n",
    "        return np.empty((0, 4)) # Return empty array with expected columns\n",
    "\n",
    "    return np.array(data_list)\n",
    "\n",
    "# --- Langchain Tool Definition ---\n",
    "@tool\n",
    "def visualize_oceanwave_data(data_directory: str, output_gif_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Visualizes OceanWave3D simulation data found in the specified directory\n",
    "    and saves the animation as a GIF file.\n",
    "\n",
    "    Args:\n",
    "        data_directory (str): The path to the directory containing the OceanWave3D\n",
    "                              output files (e.g., 'fort.10', 'fort.11', ...).\n",
    "        output_gif_path (str): The full path where the output GIF animation\n",
    "                               should be saved (e.g., '/path/to/OceanWave.gif').\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating success and the path to the saved GIF,\n",
    "             or an error message if visualization failed.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to visualize OceanWave3D data from: {data_directory}\")\n",
    "    print(f\"Output will be saved to: {output_gif_path}\")\n",
    "\n",
    "    try:\n",
    "        # === FILE COLLECTION ===\n",
    "        file_pattern = os.path.join(data_directory, \"fort.1*\") # Standard pattern\n",
    "        # Use glob to find files matching the pattern\n",
    "        files = glob.glob(file_pattern)\n",
    "        # Filter out any unexpected files if necessary (like .123 from original code)\n",
    "        files = [f for f in files if '.123' not in os.path.basename(f)]\n",
    "        # Sort files numerically based on the part after 'fort.'\n",
    "        try:\n",
    "             files = sorted(files, key=lambda x: int(os.path.basename(x).split('.')[-1]))\n",
    "        except ValueError:\n",
    "             print(\"Warning: Could not sort files numerically. Using default glob order.\")\n",
    "             files = sorted(files) # Fallback sorting\n",
    "\n",
    "        if not files:\n",
    "            return f\"‚ùå Error: No 'fort.1*' files found in directory: {data_directory}\"\n",
    "        print(f\"Found {len(files)} files to process.\")\n",
    "\n",
    "        # === PARSE FIRST FILE FOR SETUP ===\n",
    "        try:\n",
    "            first_data = _parse_oceanwave_file(files[0])\n",
    "            if first_data.shape[0] == 0:\n",
    "                 return f\"‚ùå Error: First file '{files[0]}' is empty or could not be parsed.\"\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error parsing first file '{files[0]}': {e}\"\n",
    "\n",
    "        x_values = first_data[:, 0]\n",
    "        y_values = first_data[:, 1]\n",
    "        unique_x = np.unique(x_values)\n",
    "        unique_y = np.unique(y_values)\n",
    "        nx = len(unique_x)\n",
    "        ny = len(unique_y)\n",
    "        rows = first_data.shape[0]\n",
    "        can_reshape = (nx * ny == rows)\n",
    "\n",
    "        grid_shape = None\n",
    "        if can_reshape:\n",
    "            print(\"Data appears to be on a regular grid. Using meshgrid.\")\n",
    "            X, Y = np.meshgrid(unique_x, unique_y)\n",
    "            # Ensure correct shape (rows=Y, columns=X)\n",
    "            grid_shape = (ny, nx) # Correct order for numpy reshape\n",
    "        else:\n",
    "            print(\"Data does not form a regular grid or dimensions mismatch. Using scatter plot.\")\n",
    "            # Use raw data points directly for scatter plot\n",
    "            X = x_values\n",
    "            Y = y_values\n",
    "            grid_shape = None # Explicitly mark as not gridded\n",
    "\n",
    "        # === INITIAL PLOT SETUP ===\n",
    "        plt.rcParams['figure.figsize'] = [12, 8] # Set figure size\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.view_init(elev=30, azim=-60) # Set initial view angle\n",
    "\n",
    "        # Initial plot element (surface or scatter)\n",
    "        plot_element = None\n",
    "        if grid_shape:\n",
    "            # Reshape Z data according to the derived grid shape\n",
    "            Z_initial = first_data[:, 2].reshape(grid_shape)\n",
    "            plot_element = ax.plot_surface(X, Y, Z_initial, cmap='viridis', linewidth=0, antialiased=True, alpha=0.8)\n",
    "        else:\n",
    "            # Z data remains a 1D array for scatter\n",
    "            Z_initial = first_data[:, 2]\n",
    "            plot_element = ax.scatter(X, Y, Z_initial, c=Z_initial, cmap='viridis')\n",
    "\n",
    "        # Add color bar\n",
    "        fig.colorbar(plot_element, ax=ax, shrink=0.5, aspect=10, label='Surface Elevation Œ∑') # Adjusted aspect\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Œ∑ (Surface Elevation)')\n",
    "        ax.set_title(f'Ocean Surface Elevation - Frame 0')\n",
    "        # Set aspect ratio for better visualization\n",
    "        ax.set_box_aspect([np.ptp(unique_x), np.ptp(unique_y), np.ptp(Z_initial) if Z_initial.size > 0 else 1])\n",
    "\n",
    "\n",
    "        # === DETERMINE GLOBAL Z LIMITS ===\n",
    "        print(\"Sampling files to determine Z limits...\")\n",
    "        z_mins, z_maxs = [], []\n",
    "        # Sample a limited number of files for performance\n",
    "        sample_files = files[:min(20, len(files))]\n",
    "        for i, file in enumerate(sample_files):\n",
    "            try:\n",
    "                data = _parse_oceanwave_file(file)\n",
    "                if data.shape[0] > 0:\n",
    "                    z_mins.append(np.min(data[:, 2]))\n",
    "                    z_maxs.append(np.max(data[:, 2]))\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error sampling file {file} for Z limits: {e}\")\n",
    "\n",
    "        if not z_mins or not z_maxs:\n",
    "             # Fallback if sampling failed or all sampled files were empty/bad\n",
    "             if first_data.shape[0] > 0:\n",
    "                 z_min_global = np.min(first_data[:, 2])\n",
    "                 z_max_global = np.max(first_data[:, 2])\n",
    "             else: # Should not happen due to earlier check, but as a safeguard\n",
    "                 z_min_global, z_max_global = -1, 1\n",
    "                 print(\"Warning: Could not determine Z limits automatically. Using default [-1, 1].\")\n",
    "        else:\n",
    "             z_min_global = min(z_mins)\n",
    "             z_max_global = max(z_maxs)\n",
    "\n",
    "        z_range = z_max_global - z_min_global\n",
    "        if z_range < 1e-6: z_range = 1 # Avoid zero range\n",
    "        # Add some padding to the limits\n",
    "        z_min_final = z_min_global - z_range * 0.15\n",
    "        z_max_final = z_max_global + z_range * 0.15\n",
    "        ax.set_zlim(z_min_final, z_max_final)\n",
    "        print(f\"Global Z limits set to: [{z_min_final:.2f}, {z_max_final:.2f}]\")\n",
    "\n",
    "\n",
    "        # === ANIMATION UPDATE FUNCTION ===\n",
    "        def update(frame):\n",
    "            # Use 'nonlocal plot_element' if you need to modify the specific plot object\n",
    "            # But clearing and replotting is often simpler for complex plots\n",
    "            ax.clear() # Clear previous frame's contents\n",
    "\n",
    "            try:\n",
    "                data = _parse_oceanwave_file(files[frame])\n",
    "                if data.shape[0] == 0:\n",
    "                    print(f\"Warning: Frame {frame} ({os.path.basename(files[frame])}) is empty or unparseable. Skipping.\")\n",
    "                    # Re-draw empty axes with labels/title to avoid blank frame\n",
    "                    ax.set_xlabel('X')\n",
    "                    ax.set_ylabel('Y')\n",
    "                    ax.set_zlabel('Œ∑ (Surface Elevation)')\n",
    "                    ax.set_title(f'Ocean Surface Elevation - Frame {frame} (Data Missing)')\n",
    "                    ax.set_zlim(z_min_final, z_max_final) # Maintain consistent Z limits\n",
    "                    ax.view_init(elev=30, azim=-60) # Maintain view angle\n",
    "                    # Maintain aspect ratio using limits from first frame or calculated ranges\n",
    "                    try:\n",
    "                        ax.set_box_aspect([np.ptp(unique_x), np.ptp(unique_y), z_range]) # Use calculated range\n",
    "                    except NameError: # Fallback if ranges weren't calculated properly\n",
    "                        ax.set_box_aspect([1,1,0.3]) # Default aspect\n",
    "                    return [] # Return empty list for blitting if enabled, or just return\n",
    "\n",
    "                current_Z = data[:, 2]\n",
    "\n",
    "                local_plot_element = None\n",
    "                if grid_shape:\n",
    "                    # Ensure the data for this frame can also be reshaped\n",
    "                    if current_Z.size == nx * ny:\n",
    "                        Z_reshaped = current_Z.reshape(grid_shape)\n",
    "                        local_plot_element = ax.plot_surface(X, Y, Z_reshaped, cmap='viridis', linewidth=0, antialiased=True, alpha=0.8)\n",
    "                    else:\n",
    "                        print(f\"Warning: Frame {frame} data size mismatch. Expected {nx*ny}, got {current_Z.size}. Plotting as scatter.\")\n",
    "                        # Fallback to scatter if reshape fails for this frame\n",
    "                        local_plot_element = ax.scatter(data[:, 0], data[:, 1], current_Z, c=current_Z, cmap='viridis')\n",
    "                else:\n",
    "                    # Plot as scatter using the X, Y defined initially (which are the raw coords)\n",
    "                    local_plot_element = ax.scatter(X, Y, current_Z, c=current_Z, cmap='viridis')\n",
    "\n",
    "                # Re-apply settings for each frame after clearing\n",
    "                ax.set_zlim(z_min_final, z_max_final)\n",
    "                ax.set_xlabel('X')\n",
    "                ax.set_ylabel('Y')\n",
    "                ax.set_zlabel('Œ∑ (Surface Elevation)')\n",
    "                ax.set_title(f'Ocean Surface Elevation - Frame {frame}\\nFile: {os.path.basename(files[frame])}')\n",
    "                ax.view_init(elev=30, azim=-60) # Keep consistent view\n",
    "\n",
    "                # Try setting aspect ratio based on data ranges\n",
    "                try:\n",
    "                     ax.set_box_aspect([np.ptp(unique_x), np.ptp(unique_y), z_range])\n",
    "                except NameError: # Fallback\n",
    "                     ax.set_box_aspect([1,1,0.3])\n",
    "\n",
    "                # Return the plot elements for blitting (though blit=False is set)\n",
    "                # Returning the main plot element is good practice.\n",
    "                return [local_plot_element] if local_plot_element else []\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing frame {frame}, file {os.path.basename(files[frame])}: {e}\")\n",
    "                # Optionally, add error text to the plot for this frame\n",
    "                ax.text2D(0.5, 0.5, f'Error loading frame {frame}', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, color='red')\n",
    "                # Re-apply basic settings even on error\n",
    "                ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Œ∑')\n",
    "                ax.set_title(f'Ocean Surface Elevation - Frame {frame} (Error)')\n",
    "                ax.set_zlim(z_min_final, z_max_final)\n",
    "                ax.view_init(elev=30, azim=-60)\n",
    "                return []\n",
    "\n",
    "        # === CREATE AND SAVE ANIMATION ===\n",
    "        print(\"Creating animation (this may take a while)...\")\n",
    "        # interval=200ms -> 5 fps. blit=False is often more robust for complex 3D plots.\n",
    "        ani = FuncAnimation(fig, update, frames=len(files), interval=200, blit=False)\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        output_dir = os.path.dirname(output_gif_path)\n",
    "        if output_dir: # Only create if path includes a directory part\n",
    "             os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        print(f\"Saving animation to {output_gif_path} ...\")\n",
    "        try:\n",
    "            # Use PillowWriter for GIF saving\n",
    "            writer = PillowWriter(fps=5) # Match fps to interval: 1000ms / 200ms = 5 fps\n",
    "            ani.save(output_gif_path, writer=writer)\n",
    "            plt.close(fig) # Close the plot figure to free memory\n",
    "            print(\"Animation saved successfully.\")\n",
    "            return f\"‚úÖ Successfully generated OceanWave3D animation: {output_gif_path}\"\n",
    "        except Exception as e:\n",
    "            plt.close(fig) # Ensure figure is closed even on error\n",
    "            return f\"‚ùå Error saving animation to '{output_gif_path}': {e}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any broader errors during setup\n",
    "        plt.close(fig) # Attempt to close figure if it was created\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print full traceback for debugging\n",
    "        return f\"‚ùå An unexpected error occurred during visualization setup: {e}\"\n",
    "\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 4:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "\n",
    "def summarize_conversation(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Summarize the previous conversation and prepend the summary\n",
    "    as a SystemMessage to the beginning of the messages list.\n",
    "    Retain the last Human and AI message pair before summarization.\n",
    "    \"\"\"\n",
    "    messages_to_summarize = state.messages\n",
    "\n",
    "    summarization_prompt = [\n",
    "        SystemMessage(content=\"Please summarize the following conversation concisely, highlighting user identity, key questions, requests, and any important facts discussed. This summary will be used to provide context to the AI in future turns. Do not include conversational filler or conversational history structure (like 'Human: ...', 'AI: ...'). Just provide the summary content.\"),\n",
    "        HumanMessage(content=\"Here is the conversation to summarize:\\n\\n\" + \"\\n\".join([f\"{type(msg).__name__}: {msg.content}\" for msg in messages_to_summarize]))\n",
    "    ]\n",
    "\n",
    "    response = model.invoke(summarization_prompt)\n",
    "    summary_content = response.content\n",
    "\n",
    "    # Get last AI message\n",
    "    last_ai_message = None\n",
    "    if state.messages and isinstance(state.messages[-1], AIMessage):\n",
    "        last_ai_message = state.messages[-1]\n",
    "\n",
    "    # Get last Human message before that\n",
    "    last_human_message = None\n",
    "    for msg in reversed(state.messages[:-1]):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            last_human_message = msg\n",
    "            break\n",
    "\n",
    "    # Build new message list\n",
    "    new_messages_list = [SystemMessage(content=summary_content)]\n",
    "    if last_human_message:\n",
    "        new_messages_list.append(last_human_message)\n",
    "    if last_ai_message:\n",
    "        new_messages_list.append(last_ai_message)\n",
    "\n",
    "    # Update state\n",
    "    state.messages = new_messages_list\n",
    "    state.last_summarized_at = len(new_messages_list)\n",
    "\n",
    "    return state\n",
    "\n",
    "def summarize_state(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Summarize the conversation history in the state and update the state\n",
    "    with the summary SystemMessage and truncated messages.\n",
    "    \"\"\"\n",
    "    messages_to_summarize = state[\"messages\"]\n",
    "\n",
    "    summarization_prompt = [\n",
    "        SystemMessage(content=\"Please summarize the following conversation concisely, highlighting user identity, key questions, requests, and any important facts discussed. This summary will be used to provide context to the AI in future turns. Do not include conversational filler or conversational history structure (like 'Human: ...', 'AI: ...'). Just provide the summary content.\"),\n",
    "        HumanMessage(content=\"Here is the conversation to summarize:\\n\\n\" + \"\\n\".join([f\"{type(msg).__name__}: {msg.content}\" for msg in messages_to_summarize]))\n",
    "    ]\n",
    "\n",
    "    # Ensure 'model' is accessible\n",
    "    response = model.invoke(summarization_prompt)\n",
    "    summary_content = response.content\n",
    "\n",
    "    # Keep the summary and the last 2 original messages (last Human + last AI)\n",
    "    last_ai_message = None\n",
    "    last_human_message = None\n",
    "\n",
    "    # Find last AI message\n",
    "    if messages_to_summarize and isinstance(messages_to_summarize[-1], AIMessage):\n",
    "        last_ai_message = messages_to_summarize[-1]\n",
    "        # Find last Human message before the last AI message\n",
    "        for msg in reversed(messages_to_summarize[:-1]):\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                last_human_message = msg\n",
    "                break\n",
    "\n",
    "    # Construct new messages list: Summary + retained messages\n",
    "    new_messages_list = [SystemMessage(content=summary_content)]\n",
    "    if last_human_message:\n",
    "        new_messages_list.append(last_human_message)\n",
    "    if last_ai_message:\n",
    "        new_messages_list.append(last_ai_message)\n",
    "\n",
    "    # Return the updated state with summary and truncated messages\n",
    "    return {\"summary\": summary_content, \"messages\": new_messages_list}\n",
    "\n",
    "def route_after_assistant(state: MessagesState):\n",
    "    last_message = state.messages[-1]\n",
    "\n",
    "    # If tools are needed, route there\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    # Summarize only if enough new messages since last summary\n",
    "    SUMMARY_THRESHOLD = 6\n",
    "    current_message_count = len(state.messages)\n",
    "    last_summary_at = getattr(state, \"last_summarized_at\", 0)\n",
    "\n",
    "    if (current_message_count - last_summary_at) >= SUMMARY_THRESHOLD:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    return END\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def route_tools_or_end(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Route to tools if the last message requires them, otherwise end.\n",
    "    This is called after the assistent node.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "tools = [tavily_search_full, move_file,read_file, list_files, visualize_oceanwave_data]\n",
    "llm=ChatOpenAI(model=\"gpt-4\")\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebca80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "sys_message = SystemMessage(content=\"\"\"\n",
    "You are a helpful assistant tasked with helping users download and maintain OceanWave3D files.\n",
    "\n",
    "You may sometimes be asked to search online for relevant help or instructions.\n",
    "\n",
    "IMPORTANT:\n",
    "You should ALWAYS refer to and check the following websites first:\n",
    "- https://github.com/apengsigkarup/OceanWave3D-Fortran90/tree/botp\n",
    "- https://github.com/apengsigkarup/OceanWave3D-Fortran90/tree/botp/docker\n",
    "                            \n",
    "IMPORTANT:\n",
    "If you are unsure about any aspects of OceanWave3D, you should always look throug the github in order to find the answer.\n",
    "So before you say that you can't help or don't know, take a look at the gthub.\n",
    "\n",
    "If any of the links don't work, try:\n",
    "- Navigating around the GitHub repository\n",
    "- Exploring other branches, folders, or README files for helpful content\n",
    "\"\"\")\n",
    "\n",
    "def assistent (state:MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_message] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc703f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistent\",assistent)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistent\")\n",
    "builder.add_conditional_edges(\"assistent\",tools_condition)\n",
    "\n",
    "builder.add_edge(\"tools\",\"assistent\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f312ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddaf4869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to visualize OceanWave3D data from: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/4. semester/Fagprojekt/Fagproject-AIAgent-1/Beach2\n",
      "Output will be saved to: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif\n",
      "Found 20 files to process.\n",
      "Data appears to be on a regular grid. Using meshgrid.\n",
      "Sampling files to determine Z limits...\n",
      "Global Z limits set to: [-2.80, 2.75]\n",
      "Creating animation (this may take a while)...\n",
      "Saving animation to C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif ...\n",
      "Animation saved successfully.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Visualize my OceanWave3D files that I have created in the folder called Beach2. The folder is: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/4. semester/Fagprojekt/Fagproject-AIAgent-1See that all fort.xxx files are relevant here.My output path is: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  visualize_oceanwave_data (call_XonNZONLjBukyTMIwKFki1XG)\n",
      " Call ID: call_XonNZONLjBukyTMIwKFki1XG\n",
      "  Args:\n",
      "    data_directory: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/4. semester/Fagprojekt/Fagproject-AIAgent-1/Beach2\n",
      "    output_gif_path: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: visualize_oceanwave_data\n",
      "\n",
      "‚úÖ Successfully generated OceanWave3D animation: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great news! Your OceanWave3D simulation data has been successfully visualized and the animation has been saved as a GIF file. You can find it under the following path: \n",
      "`C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif`\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\":\"Check OceanWave files\"}}\n",
    "\n",
    "messages = [HumanMessage(content=\"Visualize my OceanWave3D files that I have created in the folder called Beach2. The folder is: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/4. semester/Fagprojekt/Fagproject-AIAgent-1\" \\\n",
    "                                \"See that all fort.xxx files are relevant here.\" \\\n",
    "                                \"My output path is: C:/Users/Bruger/OneDrive - Danmarks Tekniske Universitet/Skrivebord/OceanWave.gif\")]\n",
    "\n",
    "messages = react_graph.invoke({\"messages\":messages})\n",
    "\n",
    "for m in messages ['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
